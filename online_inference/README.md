Для локальной сборки образа небходимо выполнить в корне проекта:

``` python setup.py sdist ```

```  docker build -t online_inference -f online_inference/Dockerfile . ```

Для пуллинга и поднятия inference:

```docker pull panda06/online_inference:latest```

```docker run -p 8080:8080 panda06/online_inference:latest```

№|  Задание | Баллы
--- | --- | ---
0| ветку назовите homework2, положите код в папку online_inference | -
1 | Оберните inference вашей модели в rest сервис(вы можете использовать как FastAPI, так и flask, другие желательно не использовать, дабы не плодить излишнего разнообразия для проверяющих), должен быть endpoint /predict | 3 балла
2 | Напишите тест для /predict |  3 балла
3 | Напишите скрипт, который будет делать запросы к вашему сервису | 2 балла
4 | Сделайте валидацию входных данных | -
5 | Напишите dockerfile, соберите на его основе образ и запустите локально контейнер(docker build, docker run), внутри контейнера должен запускать сервис, написанный в предущем пункте, закоммитьте его, напишите в readme корректную команду сборки | 4 балла
6 | Оптимизируйте размер docker image | -
7 | опубликуйте образ в https://hub.docker.com/, используя docker push (вам потребуется зарегистрироваться) | 2 балла
8 | напишите в readme корректные команды docker pull/run, которые должны привести к тому, что локально поднимется на inference ваша модель | 1 балл
9 | проведите самооценку | 1 доп балл
10 | создайте пулл-реквест и поставьте label -- hw2 | -
 - | Итого | 16 